{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86242813-8726-4704-9ce4-5e43c4057365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67e8bef-ea82-45cb-822b-e29d86a3b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        paragraphs = []\n",
    "        buffer = []\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                buffer.append(line)\n",
    "            elif len(buffer):\n",
    "                paragraphs.append((\" \").join(buffer))\n",
    "                buffer = []\n",
    "        if len(buffer):\n",
    "            paragraphs.append((\" \").join(buffer))\n",
    "        return paragraphs\n",
    "\n",
    "\n",
    "def save_embeddings(filename, embeddings):\n",
    "    # create dir if it doesn't exist\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    # dump embeddings to json\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    # check if file exists\n",
    "    if not os.path.exists(f\"embeddings/{filename}.json\"):\n",
    "        return False\n",
    "    # load embeddings from json\n",
    "    with open(f\"embeddings/{filename}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    # check if embeddings are already saved\n",
    "    if (embeddings := load_embeddings(filename)) is not False:\n",
    "        return embeddings\n",
    "    # get embeddings from ollama\n",
    "    embeddings = [\n",
    "        ollama.embeddings(model=modelname, prompt=chunk)[\"embedding\"]\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    # save embeddings\n",
    "    save_embeddings(filename, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "\n",
    "    # print(needle, haystack[0])\n",
    "    # print(np.dot(needle, haystack[0]))\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)\n",
    "\n",
    "\n",
    "def rag_function(prompt):\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"You are a helpful reading assistant who answers questions\n",
    "        based on snippets of text provided in context. Answer only using the context provided,\n",
    "        being as concise as possible. If you're unsure, just say that you don't know.\n",
    "        Do not give answers that are outside the context given.\n",
    "        Answer in about 150 words for each prompt.\n",
    "        Context:\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    filename = \"data.txt\"\n",
    "    paragraphs = parse_file(filename)\n",
    "\n",
    "    embeddings = get_embeddings(filename, \"nomic-embed-text\", paragraphs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    prompt_embedding = ollama.embeddings(model=\"nomic-embed-text\", prompt=prompt)[\"embedding\"]\n",
    "    most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "\n",
    "   \n",
    "    response = ollama.chat(\n",
    "    model=\"gemma:2b\" ,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT\n",
    "            + \"\\n\".join(paragraphs[item[1]] for item in most_similar_chunks),\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"\\n\")\n",
    "    print(response['message']['content'])\n",
    "    print(\"\\n\")\n",
    "    print(f\"Execution Time {end_time-start_time} \")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d52da25e-93ad-445c-b3f2-38b073a122fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sure, here's the information you requested:\n",
      "\n",
      "Sachin Tendulkar is an Indian former international cricketer who is widely regarded as one of the greatest batsmen in the history of cricket. He holds the record for receiving the most player of the match awards in international cricket and is the all-time highest run-scorer in both ODI and Test cricket.\n",
      "\n",
      "\n",
      "Execution Time 26.931724309921265 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt=\"Enlist the achievements of Sachin Tendulkar\"\n",
    "rag_function(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a95938de-2be6-4d4c-b283-933601de5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The context does not mention who is better Captain Dhoni or Sourav, so I cannot answer this question from the context.\n",
      "\n",
      "\n",
      "Execution Time 233.76730394363403 \n"
     ]
    }
   ],
   "source": [
    "prompt=\"Who is better Captain Dhoni or Sourav?\"\n",
    "rag_function(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717d57e-a4ba-4c30-8690-df15e66b97b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cc289-a567-4193-9774-27b274f9161c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
