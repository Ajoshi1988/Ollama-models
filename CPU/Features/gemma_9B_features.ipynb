{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d543542e-55b0-44d5-a6dc-dc18e77377c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import date, datetime\n",
    "from typing import Optional, Dict, List, Any\n",
    "\n",
    "import pytz\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import time\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5bcc3d-fa25-42fd-afe2-0e9bb0f6bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42067/288039917.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "/tmp/ipykernel_42067/288039917.py:16: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  raw_response = llm_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query and their types:\n",
      "\n",
      "* **Me/Aditya:**  Person (Name)\n",
      "* **Bangalore:** Location \n",
      "* **Microsoft:** Organization\n",
      "* **Apples:** Thing (Type of fruit)\n",
      "* **Data Science:** Field of study \n",
      "\n",
      "\n",
      "Let me know if you'd like me to elaborate on any of these!\n",
      "\n",
      "\n",
      "Execution Time 16.462348699569702 \n"
     ]
    }
   ],
   "source": [
    "def bot_answer(query: str):\n",
    "\n",
    "   \n",
    "    start_time=time.time()\n",
    "    prompt_template = PromptTemplate(\n",
    "\n",
    "        input_variables=[\"query\"],\n",
    "         template=\"\"\"List all the entities in the query and also mention what they are\n",
    "          Query: {query}\n",
    "                \"\"\"\n",
    "         )\n",
    "           \n",
    "\n",
    "    llm = OllamaLLM(model=\"gemma2:9b\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    raw_response = llm_chain.run(query)\n",
    "    end_time=time.time()\n",
    "    print(raw_response)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Execution Time {end_time-start_time} \")\n",
    "    return None\n",
    "\n",
    "\n",
    "query=\"Me Aditya from Bangalore is working in Microsoft, I like apples and I am interested in Data Science\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fa41bb-3439-4dd0-b019-cf6cdaf1769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query, along with their types:\n",
      "\n",
      "* **Trump** -  Person (former US President)\n",
      "* **Modi** - Person (current Prime Minister of India)\n",
      "* **Biden** - Person (current US President)\n",
      "* **India** - Country\n",
      "* **Russia** - Country\n",
      "* **USA** - Country \n",
      "\n",
      "\n",
      "Let me know if you'd like me to analyze any other aspects of the query! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 19.181145906448364 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Trump and Modi have a very understanding, unfortunately Biden is a big problem to India, Russia and USA. India needs Modi and US needs Trump\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca2c564-4cf7-4788-9fee-e8ffcc3ab639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from your query and their types:\n",
      "\n",
      "* **Propellers:**  Object (Specifically, a type of aircraft engine) \n",
      "* **PSLV:** Organization (Indian Space Research Organisation's Polar Satellite Launch Vehicle)\n",
      "* **ISRO:** Organization (Indian Space Research Organisation) \n",
      "\n",
      "\n",
      "Let me know if you have any other queries!\n",
      "\n",
      "\n",
      "Execution Time 14.561737775802612 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Propellers are important part of PSLV, ISRO relies heavily on them\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae1a1a2-407b-40c5-b8f1-451fdbaa54ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities in your query and their types:\n",
      "\n",
      "* **Elon Musk:**  PERSON \n",
      "* **Innovator:**  ROLE/TITLE (though could be argued as ABSTRACT_CONCEPT)\n",
      "* **Twitter:** ORGANIZATION\n",
      "* **Purchasing Twitter:** ACTION \n",
      "\n",
      "\n",
      "Let me know if you'd like to explore any of these further!\n",
      "\n",
      "\n",
      "Execution Time 14.097803115844727 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Elon Musk is the biggest innovator I have ever known. Purchsing twitter was a great move\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6d6474-ec5a-45ce-8570-817c5ffaf16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **extremely positive** bordering on arrogant. \n",
      "\n",
      "It expresses a strong sense of self-confidence and dominance, with claims of invincibility.  \n",
      "\n",
      "I'd estimate the sentiment strength at **95% positive**. \n",
      "\n",
      "\n",
      "Let me know if you have any other queries you'd like analyzed! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 15.330536842346191 \n"
     ]
    }
   ],
   "source": [
    "#Sentiment analyzer\n",
    "def bot_answer(query: str):\n",
    "\n",
    "   \n",
    "    start_time=time.time()\n",
    "    prompt_template = PromptTemplate(\n",
    "\n",
    "        input_variables=[\"query\"],\n",
    "         template=\"\"\"Mention te sentiment of the query, also mention the strength of sentiment in percentage\n",
    "          Query: {query}\n",
    "                \"\"\"\n",
    "         )\n",
    "           \n",
    "\n",
    "    llm = OllamaLLM(model=\"gemma2:9b\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    raw_response = llm_chain.run(query)\n",
    "    end_time=time.time()\n",
    "    print(raw_response)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Execution Time {end_time-start_time} \")\n",
    "    return None\n",
    "\n",
    "query=\"I am the king of westeros!, No one can defeat me\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f96e3c8-bb4a-449e-9542-05dc5df88657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **extremely negative**. \n",
      "\n",
      "It expresses a strong feeling of disapproval and criticism towards President Biden, using harsh language (\"mentally incompetent\") to convey that sentiment.  \n",
      "\n",
      "I would estimate the strength of sentiment to be around **95-100% negative**. \n",
      "\n",
      "\n",
      "Let me know if you'd like me to analyze any other queries! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 15.28091835975647 \n"
     ]
    }
   ],
   "source": [
    "query=\"Biden is the most mentally incompetent President I have ever seen\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383df0c0-6d47-4017-adac-f3aefb382d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **positive**. \n",
      "\n",
      "It expresses admiration for Vivek Ramaswamy's qualities (wealthy, eloquent, clear vision) and suggests a favorable outlook on his potential.  \n",
      "\n",
      "**Strength of Sentiment:** I would estimate the sentiment strength to be around **85-90% positive**. \n",
      "\n",
      "\n",
      "The language used is highly complimentary, emphasizing positive attributes. \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 16.079957485198975 \n"
     ]
    }
   ],
   "source": [
    "query=\"Vivek Ramasamy at this young age is wealthy, eloquent and has a clear vision for United states\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9a5ec-666c-4c6a-8110-bfc0696d9953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1302f-0027-4ede-be5d-06a680a26c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c21f5-a4ee-4d04-a358-10ba4850830d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
