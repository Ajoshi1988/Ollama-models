{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9662bf-dbd1-4c2c-9a36-fbcf4c7e8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import date, datetime\n",
    "from typing import Optional, Dict, List, Any\n",
    "\n",
    "import pytz\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import ollama\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import time\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c667561-3fa5-492b-92a5-673f4d2c715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30569/288039917.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "/tmp/ipykernel_30569/288039917.py:16: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  raw_response = llm_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query and their types:\n",
      "\n",
      "* **Me/Aditya** -  Person \n",
      "* **Bangalore** - Location\n",
      "* **Microsoft** - Organization\n",
      "* **Apples** - Food/Fruit\n",
      "* **Data Science** - Field of Study \n",
      "\n",
      "\n",
      "Let me know if you'd like to explore any of these entities further!\n",
      "\n",
      "\n",
      "Execution Time 2.912651300430298 \n"
     ]
    }
   ],
   "source": [
    "def bot_answer(query: str):\n",
    "\n",
    "   \n",
    "    start_time=time.time()\n",
    "    prompt_template = PromptTemplate(\n",
    "\n",
    "        input_variables=[\"query\"],\n",
    "         template=\"\"\"List all the entities in the query and also mention what they are\n",
    "          Query: {query}\n",
    "                \"\"\"\n",
    "         )\n",
    "           \n",
    "\n",
    "    llm = OllamaLLM(model=\"gemma2:9b\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    raw_response = llm_chain.run(query)\n",
    "    end_time=time.time()\n",
    "    print(raw_response)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Execution Time {end_time-start_time} \")\n",
    "    return None\n",
    "\n",
    "\n",
    "query=\"Me Aditya from Bangalore is working in Microsoft, I like apples and I am interested in Data Science\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b37bf5-db8e-48e9-868c-813964414801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query, along with their types:\n",
      "\n",
      "* **Trump:** Person (former President of the United States)\n",
      "* **Modi:** Person (Prime Minister of India)\n",
      "* **Biden:** Person (current President of the United States)\n",
      "* **India:** Country\n",
      "* **Russia:** Country\n",
      "* **USA:**  Country \n",
      "\n",
      "\n",
      "Let me know if you'd like me to analyze any other aspects of this query! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 3.5368478298187256 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Trump and Modi have a very understanding, unfortunately Biden is a big problem to India, Russia and USA. India needs Modi and US needs Trump\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd86d856-acf0-480e-948d-e8134c26c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query and their types:\n",
      "\n",
      "* **Propellers** -  _Object_: Physical components used for propulsion.\n",
      "* **PSLV** - _Organization/Artifact_:  The Polar Satellite Launch Vehicle, an Indian rocket. \n",
      "* **ISRO** - _Organization_: The Indian Space Research Organisation. \n",
      "\n",
      "\n",
      "Let me know if you have any other text you'd like me to analyze!\n",
      "\n",
      "\n",
      "Execution Time 3.3299272060394287 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Propellers are important part of PSLV, ISRO relies heavily on them\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906a7074-a262-437f-92c3-b76301f652c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the entities from the query, along with their types:\n",
      "\n",
      "* **Elon Musk:**  PERSON\n",
      "* **innovator:**  ROLE/TITLE \n",
      "* **twitter:** ORGANIZATION \n",
      "\n",
      "\n",
      "Let me know if you'd like me to break down any of these further! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 2.3688206672668457 \n"
     ]
    }
   ],
   "source": [
    "#Entity recognition\n",
    "query=\"Elon Musk is the biggest innovator I have ever known. Purchsing twitter was a great move\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b3bee8-31db-4da0-b3ec-c11075e7a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **extremely positive** bordering on arrogant.  \n",
      "\n",
      "It expresses a strong sense of self-confidence and dominance. \n",
      "\n",
      "**Strength of Sentiment:**  I'd estimate the sentiment strength at **95% positive**. \n",
      "\n",
      "\n",
      "The exclamation points and boastful language (\"king of Westeros\", \"No one can defeat me\") clearly indicate a highly positive, even overconfident, feeling. \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 3.327922821044922 \n"
     ]
    }
   ],
   "source": [
    "#Sentiment analyzer\n",
    "def bot_answer(query: str):\n",
    "\n",
    "   \n",
    "    start_time=time.time()\n",
    "    prompt_template = PromptTemplate(\n",
    "\n",
    "        input_variables=[\"query\"],\n",
    "         template=\"\"\"Mention te sentiment of the query, also mention the strength of sentiment in percentage\n",
    "          Query: {query}\n",
    "                \"\"\"\n",
    "         )\n",
    "           \n",
    "\n",
    "    llm = OllamaLLM(model=\"gemma2:9b\")\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    raw_response = llm_chain.run(query)\n",
    "    end_time=time.time()\n",
    "    print(raw_response)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Execution Time {end_time-start_time} \")\n",
    "    return None\n",
    "\n",
    "query=\"I am the king of westeros!, No one can defeat me\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e118c755-1460-40e1-9d9d-1a8111899876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **extremely negative**. \n",
      "\n",
      "It expresses a strong opinion of disapproval and  condemnation towards President Biden. The language used (\"most mentally incompetent\") is highly charged and carries a significant negative weight.\n",
      "\n",
      "I'd estimate the strength of sentiment to be around **95% negative**. \n",
      "\n",
      "\n",
      "Let me know if you have other queries you'd like analyzed! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 3.158240556716919 \n"
     ]
    }
   ],
   "source": [
    "query=\"Biden is the most mentally incompetent President I have ever seen\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "926a638c-dff2-4426-bbc5-210fc550e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query is **positive**. \n",
      "\n",
      "It expresses admiration and approval for Vivek Ramasamy's qualities:\n",
      "\n",
      "* **Wealthy:**  While wealth itself isn't inherently positive, it's presented here as a fact alongside other positive attributes.\n",
      "* **Eloquent:** This implies strong communication skills and persuasiveness.\n",
      "* **Clear vision for the United States:** This suggests competence, leadership potential, and forward-thinking.\n",
      "\n",
      "**Strength of Sentiment:** I'd estimate the sentiment strength to be around **80%**.  The use of words like \"wealthy,\" \"eloquent,\" and \"clear vision\" are strong indicators of positive regard. \n",
      "\n",
      "\n",
      "Let me know if you have any other queries! \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 5.53739857673645 \n"
     ]
    }
   ],
   "source": [
    "query=\"Vivek Ramasamy at this young age is wealthy, eloquent and has a clear vision for United states\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e78f39-a504-4d04-b2c3-a45e1fd7c7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the query \"I cannot stand the sight of you\" is **extremely negative**. \n",
      "\n",
      "It expresses intense dislike and aversion.  \n",
      "\n",
      "**Sentiment Strength:** 95%  \n",
      "\n",
      "\n",
      "The phrase \"cannot stand\" indicates a very strong level of negativity and intolerance.  \n",
      "\n",
      "\n",
      "\n",
      "Execution Time 2.3687705993652344 \n"
     ]
    }
   ],
   "source": [
    "query=\"I cannot stand the sight of you\"\n",
    "bot_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af638241-b179-46ce-8fe0-da3a134a4a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69dfe8d-ddb3-4dff-8a04-fc7483466792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e491e-8339-446d-9352-ec1b03944ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
